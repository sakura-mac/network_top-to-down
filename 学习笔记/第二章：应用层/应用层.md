## 协议原理

### 网络应用程序体系结构

对于web app而言，协议的分层让我们不关注底层的实施，只需要调用底层的服务来实现本层的业务。因此这里有两个模型

- client-server
- p2p

前者相当于集权管理，各个客户端并不相互通信。为此需要构建大的数据中心，比如搜索引擎等。

后者则可以相互通信，比如迅雷的大家一起加速等。对于一个主机而言，对方上传，即对方标识为服务器，相反，则标识为客户端。因此拥有了可扩展性，同时不需要数据中心这样的成本开销。虽然自己随着请求增多而增加负载，但是给自己提供数据的也多。人人为我，我为人人。

### 进程通信

对于应用来讲，一个应用和另一个应用的通信实际上时进程之间的通信，下面自里向外描述了一些内容

1. 模型：client-server进程：发起通信为客户，等待联系为服务器。

   这种程度描述相当接近我们实际编写的代码，比如python爬虫就是一个client-server进程的请求与回应。

2. 进程和计网之间的接口：假设你明白套接字的定义，这样的一个接口向网络接收发送message

   你能控制应用层的一切，但是对于运输层的权限有限：

   - 选择运输层的协议
   - 设定运输层的参数：比如max cache 和max message length

3. 进程寻址：

   - 主机地址
   - 接收的标识符

   

### 运输层协议

为什么应用层的内容需要讲运输层，不直接讲应用层协议？这是因为上层协议需要选择和使用下层协议带来的服务。所以需要简单讲讲

一个运输层协议能够对应用提供怎样的服务？很显然，想想TCP/IP和UDP我们就知道从数据传输的角度考虑：可靠性，吞吐量，定时和安全性

- 可靠性

分组在交换的等待队列满时会丢包。因此对于数据无损这部分要求必须要进行实现，即TCP协议，没有这么严格就UDP协议

- 吞吐量

我们知道吞吐量被瓶颈链路所约束。但再复杂一点看，并发情况下吞吐量还会被其他用户约束，我们就用可用吞吐量这个概念来描述。对于稳定吞吐量的要求，我们用宽带敏感应用来描述。如果可用吞吐量不够，就慢慢编码等待或者不发送。当然与之对应也有弹性应用，比如邮件，文件传输。

- 定时

定时保证的例子：游戏。如发送方的套接字的比特到接收方的套接字延时不超过100ms

- 安全性

加密传输，完整传输，端点鉴别等。



讲解一下TCP和UDP

1. TCP：两个服务：面向连接和可靠数据传输服务。前者通过握手阶段连接，报文发送结束后拆除连接。后者保证不重不漏不乱不错，但是本身tcp不加密这是通过套接字来加强实现的。同时，TCP拥有拥塞控制
2. UDP：轻量级，就是快，啥也咩有：没有拥塞控制没有可靠性，没有握手，“三无”。



### 应用层协议

- 类型
- 语义
- 语法：报文的字段的描述
- 规则

有些应用层协议是由RFC决定，比如http就是一个RFC

当然你别忘了我们一直讲的是协议，而不是网络应用，这是包含关系。

## Web和HTTP

这里的web和http发生地点在网页上，我们可以简单概括：有一些对象的网页。这里的对象可以是文本，是图片，是一些视频。很显然这些对象都有引用，即url。

![](https://tva1.sinaimg.cn/large/008i3skNly1gtf258d3w7j60va06kgmb02.jpg)

### HTTP

定义：超文本传输协议，即在应用层的一个协议。

从传输上看，我们在client-server模型使用了应用层的http协议来传输数据，client负责请求，server负责回应。而http紧接着会使用tcp的传输层协议来保证连接。具体使用如下

- client初始化tcp：创建socket，端口80
- server接收成功信号（比喻：hi， hi！）
- 数据的请求和回应
- 关闭tcp连接



http特点：

- 使用tcp协议

- 无状态

  

连接方式：

- 非持续性传输
- 持续性传输

先看非持续性传输

![](https://tva1.sinaimg.cn/large/008i3skNly1gtf218n5uyj61120p00xp02.jpg)

![](https://tva1.sinaimg.cn/large/008i3skNly1gtf21cfuqkj60yy0g0mym02.jpg)

1. 创建TCP连接
2. 发送请求
3. 回应请求
4. 服务器通知断开TCP连接：直到客户端收到所有报文
5. 客户端收到相应，关闭连接

这里我们看到大体结构仍然是请求与回应，创建tcp和关闭tcp。那么非持续性连接和持续性连接的区别到底在哪？

​	在于单次TCP传输对象个数，很显然前者一次一个，后者多个。给出回应的简单描述：

![](https://tva1.sinaimg.cn/large/008i3skNly1gtf2cuapn3j60jo0l4dh002.jpg)

这里引入RTT概念：一个组从请求到回应的时间(我们这里只有两次handshaking，被简化了)

那么我们可以看到这里整个流程从请求到回应的时间(简单来看)：
$$
response time = 2RTT + Ttrans
$$
为了加快流程，持续性连接在传输一个对象之后并不关掉连接，而是保留，从而实现单次tcp连接传输多个对象的目标，从数学上看第二次开始第一份RTT在第一次请求后会消失，从而节省时间。

### 报文格式

具体说明一下请求和回应的格式

1. 请求：![](https://tva1.sinaimg.cn/large/008i3skNly1gtf41kah4qj610g0p841k02.jpg)

这里分成三部分：

- 请求lines
- header lines
- body

其中请求line包含了请求方法和url，header lines包含了请求的对象host，user-agent，language等。

对于请求，实际上是复杂化前面等“上传即服务器”这个概念，请求也是上传，不过很显然是作为user而不是server，这很容易理解。

对于url，有绝对路径和相对路径之分，这会对后面的套接字作业有影响

对于请求的方法：

- GET
- POST
- HEAD
- DELETE

等，如果你有python爬虫的经验你就会很熟悉这些方法。



2. 回应：

![](https://tva1.sinaimg.cn/large/008i3skNly1gtf49kqgjmj610y0lyn0w02.jpg)

这里我们关注这个200。对于一个请求的回应我们最怕拒绝，比如我们常见的404，而这里的200意味着请求成功。列出一些情况：![](https://tva1.sinaimg.cn/large/008i3skNly1gtf4alqkjdj610g0fojuq02.jpg)

接下来我们做个小实验，远程连接一个web应用，然后看回应是什么。

![](https://tva1.sinaimg.cn/large/008i3skNly1gtf4bpgac7j61080nkn1l02.jpg)

### cookie

我们回到HTTP的特点：除了TCP连接，还有无状态。这里的无状态意思是不保存用户的状态。即：每次你登陆网页都好像第一次登陆一样。

为了提高服务质量，引入cookie，即本地存储一些信息，让你再次访问一个网站的时候仿佛吃了cookie（饼干）一样贴心，比如淘宝商品推荐会逐步接近你的口味。

因此我们回到那个HTTP模型，这一次我们为了cookie加入一个数据库，来分析cookie。

![](https://tva1.sinaimg.cn/large/008i3skNly1gtf4hozpqej610c0p6gpv02.jpg)

这里我们可以看到第一次请求后回应包含了cookie，而下一次请求会包含着cookie，数据库负责比对cookie然后让server做出更贴心的回应。

### Web caches(代理服务器)

从速度角度看，现在我们有了持续性连接，还能否更快？

答案是缓存，即在服务器和客户端之间加入一个缓存，减少传输时间。

![](https://tva1.sinaimg.cn/large/008i3skNly1gtf4o1tibgj612c0q0aft02.jpg)

假设0.4部分HTTP连接向缓存，剩余0.6向服务器。因此在不考虑增加带宽的情况下（贵），更加便宜的web缓存可以让这部分时延忽略不计。

让我们具体看看：

1. 浏览器创建一个面向缓存的TCP，发送一个HTTP请求
2. 缓存比对成功回应对象
3. 比对失败则向服务器请求
4. 回应仍然先通过缓存，进行更新，然后回到客户端

Web缓存通常由ISP配置，比如校园网的配置会让浏览器指向这个缓存。

### 条件GET方法

不过缓存的故事还没结束。既然是缓存，为什么内容不能是旧的？

因此接下来的GET方法即证明是否最新。

简单来说，就是假如

1. HTTP请求是GET方法
2. 并且请求报文包括

```
If-Modified-Since://包括了最近一次修改的时间
```

那么就会进行检查缓存最新。

让我们看看过程：

1. 假设请求内容已经缓存，并且上次服务器对缓存的回应包括了日期

   ```
   Last-Modified://date
   ```

   

2. 新的请求仍然通过代理服务器

   ```
   GET /fruit/kiwi.gif HTTP/1.1
   Host:www.exotiquecuisine.com
   If-modified-since://date
   ```

   

3. 代理服务器向服务器发送请求并得到回应：缓存是否最新

   ```
   HTTP/1.1 304 Not Modified
   Date： Sat， 10 Oct 2015 15:34:29
   Server： Apache/1.3.0 （Unix）
   （empty） body
   ```

自此，代理服务器的功能才算初步完整。回到时延我们发现，代理服务器因此并没有消去RTT，而是概率消去了Ttrans。



## 电子邮件SMTP

### 定义

邮件系统包括三个组成部分：

- 用户代理
- 邮件服务器
- 简单邮件传输协议

那么这三个组成部分如何在传输邮件中发挥作用呢？

看看流程：

1. 用户代理向服务器发送邮件
2. 邮件存放在服务器的外出报文队列中
3. 另一个人读邮件时候他的用户代理从自己的服务器取得报文

有一些问题：

- 用户代理是什么：你觉得用户会自己选择协议，发送命令到服务器吗，当然是使用比如163邮箱软件代做。你只要记得用户名和密码就行。而系统中服务器就由相应ISP提供。
- 如果服务器报文队列发送失败怎么办：约定重发次数和时间间隔

### SMTP

对于邮件系统来说，和前面理解不太一样的部分就是一个系统包含了用户代理和服务器。是邮件的传输是通过两次协议传输到对方服务器。听起来有点麻烦。

根据这个流程，SMTP就作为应用层的传输协议非常有必要，同样的，他通过TCP协议来享受可靠数据传输服务。

但是仍然，SMTP叫做简单邮  件传输协议的原因是：传输能力太弱了->他限定了7位ASCII，这意味着图片或者视频是奢望。

不过先看看SMTP的流程吧

1. Alice调用邮件代理程序，并且用户给出Bob的邮箱地址(你写邮件要知道对方的邮箱地址)
2. 用户代理发送到邮件服务器，报文被放到报文队列中
3. SMTP客户端发现了这个报文，于是创造一个TCP连接准备传输
4. 在握手后，SMTP通过TCP连接发送报文
5. Bob调用用户代理阅 读报文

给出服务器之间的SMTP连接

```
     S: 220 hamburger.edu 
     C: HELO crepes.fr 
     S: 250  Hello crepes.fr, pleased to meet you 
     C: MAIL FROM: <alice@crepes.fr> 
     S: 250 alice@crepes.fr... Sender ok 
     C: RCPT TO: <bob@hamburger.edu> 
     S: 250 bob@hamburger.edu ... Recipient ok 
     C: DATA 
     S: 354 Enter mail, end with "." on a line by itself 
     C: Do you like ketchup? 
     C: How about pickles? 
     C: . 
     S: 250 Message accepted for delivery 
     C: QUIT 
     S: 221 hamburger.edu closing connection

```

在创建TCP连接后，这些S和C即向套接字发送以上内容。邮件内容包括“Do you like ketchup? 
     How about pickles? ”

- 第一行为**tcp成功连接后**服务器将主机名和成功信息返回，第二行客户端打个招呼SMTP命令“helo”表明主机名，对方回应
- 紧接着从MAIL FROM**命令**开始邮件报文，以.结束，在所有邮件发送完毕后发送QUIT命令（很像持续性连接是吧）
- 关闭TCP连接

建议自己建立一次SMTP连接：

```
telnet serverName 25 //serverName为邮件服务器的名称，25为端系统接受协议的port
```

然后在合适时候发送SMTP命令（本人已写相关文档）。做本章的关于实现简单的用户代理的编程作业（python套接字编程作业）（）



最后有个小细节，回顾第一章我们会知道各个ISP相连，那么中间服务器的存在也理所应当（不是代理服务器）。不过对于邮件传输，没有中间服务器。假设你在香港，对方在洛杉矶，你们的服务器也是直接相连的。

### 和HTTP对比

很显然，二者发送文件时候都可以说是持续性连接，但是也有区别

1. HTTP主要是拉协议，SMTP主要是推协议
2. SMTP要求报文7bitASCII格式
3. HTTP封装所有对象到报文中，而SMTP存放所有对象到一个报文

对于第一点，HTTP被使用时，用户从服务器获取文件，而SMTP被使用时，用户向服务器推送文件

对于第三点，HTTP一个报文一个对象，比如图片等，而SMTP一封邮件当然所有对象都在一个报文（非常地落后）



### 报文格式

首先是报文header lines

```
From: alice@crepes.fr
To: bob@hamburger.edu
Subject: Searching for the meaning of life
```

看起来非常地清楚，只显示了邮箱地址和主题

紧接着一个空白行，然后就是ASCII格式的报文体

这里的格式跟是由命令以及输入的参数编码而成的。

### 访问协议

假设Bob服务器得到了报文，接着讨论Bob如何从用户代理阅读这些报文。同样也有相关的协议来规范。

首先我们要思考一些问题

1. 以往的服务器都不在本地，如果本地会怎样
2. 都是SMTP协议，用户代理是否可以绕开服务器直接发送给对方服务器

第一个问题：你得联网，否则对方可能发送失败

第二个问题：不行，因为在对方服务器对用户代理是未知的。

对于多个同一份报文SMTP规定了如何通过多个服务器来到达对方服务器。

接着我们看用户如何获得服务器的报文

- POP3

​      作为一个简单的邮件访问协议。

​      端口110

分为以下几个步骤

1. 特许阶段：即通过用户名和密码登录用户代理
2. 事务处理阶段：阅读和删除标记
3. 更新阶段：发出quit命令后删除

对于POP3，通常需要设置对于服务器的报文是“下载并保留”还是“下载并删除”，来清空接收缓冲区队列

```
//特许阶段
S: +OK POP3 server ready 
C: user bob 
S: +OK 
C: pass hungry 
S: +OK user successfully logged on
//事务处理阶段
C: list 
S: 1 498 
S: 2 912 
S: . 
C: retr 1 
S: <message 1 contents>
S: . 
C: dele 1 
C: retr 2 
S: <message 1 contents>
S: . 
C: dele 2 
C: quit 
//更新阶段
S: +OK POP3 server signing off
```



- IMAP

  端口143

  和POP3对比：
  
  - 相比于“下载并保留”的设置，IMAP统一保留在服务器
  - 增加了文件系统，让用户可以以管理远程文件夹方式加强对邮件的访问。   
  - 保留状态信息：POP3的更新永远在用户会话之后，IMAP则相反 

### 基于web的电子邮件

在用户代理到服务器中，使用了HTTP协议（哈没想到吧），而服务器之间仍然使用SMTP协议。



## DNS：因特网的目录服务

DNS产生的唯一原因就是主机识别用ip来记太累了，因此采用主机名甚至主机别名的方法识别，因此他提供了目录服务，叫做：域名系统。

DNS同样是包含一个应用层的协议，即主机获得ip地址。其他应用无时无刻不使用着DNS里的协议。假设你使用邮件系统，服务器回应部分你只能得到主机名，而主机名提供的信息量少并且无法识别，因此需要DNS来提供目录服务。

DNS也是一个client-server模型，DNS各个服务器是数据库，存储了主机名-ip地址这样的键值对。

DNS使用53号端口，使用UDP，因此连接没有TCP那样的RTT时延。

### DNS提供的服务

1. 主机-ip映射
2. 主机别名
3. 邮件服务器别名
4. 负载分配：客户通常向ip地址最前面的服务器发送HTTP请求，因此DNS可以分配返回的ip顺序，来控制负载

那么DNS具体怎么工作？

### DNS工作原理概述

DNS是一个分层组织分布式系统，而不是集中式，主要原因如下：

1. 单点故障
2. 通信容量
3. 远距离
4. 维护

因此分布式DNS是必然的，不过怎么查询？

DNS服务器分为以下三个层次

- 根DNS服务器
- TLD（顶流）服务器
- 权威服务器
- 本地服务器：不算，但是很重要

通常首先进入根服务器，然后依次流经TLD服务器，权威服务器，最后返回客户端

本地服务器的唯一作用就是转发，指向三个层次的服务器转发客户端的主机名。

通过本地服务器，DNS有两种查询方法。

第一种：递归查询，即以目录服务作为函数传参不同的主机名得到ip地址，然后根据递归链返回到查询的DNS客户端。



第二种也就是我们常用的：使用本地服务器，其余所有服务器查询后直接返回到本地服务器。而只有本地服务器和DNS客户端之间是递归也就是递归+迭代





从以上的图我们可以推测，本地服务器天然存储根服务器的ip地址，无论是哪种查询方法，后续的TLD服务器，权威服务器，都是根据上一层次得到的。最后应该有八次查询



理论上DNS查询迭代和递归都可以使用，为什么用第二种方法？个人猜测是纯递归查询需要更长的时间，并且对每一级间隔时间响应和请求短时间要求高。

不过DNS查询还可以更快，模仿代理服务器我们使用缓存，即每次查询后缓存查询，唯一不同的地方在于缓存定期清除。



### DNS记录和报文

再深入一点，让我们看看DNS到底存储了什么样的键值对和具体报文：

RR（资源记录）

format：（Name， Value，Type，TTL）

- TTL是缓存的删除时间，对于现在看DNS服务器三个层次并不是非常重要
- TYPE决定了Name和Value的语义

TYPE

- A :Name=主机名（如relay1.bar.foo.com），Value=ip地址
- NS：Name=域名（如foo.com），Value=权威服务器的主机名
- CNAME：Name=主机别名，Value=主机名
- MX：Name=服务器别名，Value=主机名

给出一些记录和服务器的具体关系

- 一个公司邮件服务器可以和其他服务器使用同一个别名，因此DNS客户请求邮件服务器使用MX，其他服务器使用CNAME
- 对于存储特定主机名的权威服务器，存储A记录；如果不特定（如TLD），存储NS和A（为了找到Value对应的ip）来指向权威服务器

报文

DNS作为基于数据库提供的目录服务，报文只有两种，请求和响应

- 首部 12B
- 查询信息
- 查询RR
- 权威区域   
- 附加区域：MX记录情况下A记录会放在这里

我们可以直接使用nslookup来直接向某些DNS服务器查询,在wireshark实验里（）

### 插入数据库

现实社会DNS请求一般第一个指向TLD，因此分为以下步骤

1. 你拥有权威DNS服务器，并配置A记录，并能够动态更新
2. 向机构提供基本+辅助 的权威DNS 的（主机名，ip）
3. 上一层次：TLD：保证机构有有NS+A记录

## P2P文件分发

考虑到前面的协议都使用client-server模型，这严重依赖服务器，因此我们来考虑更有扩展性的东西，即体量更小，更受用户控制的：P2P，他的协议是BitTorrent

### P2P体系结构的扩展性

P2P拥有自扩展性，让我们比对一下两种模型的最差情况下分发时间下界



直接原因就在于P2P的对等方既可以是服务器也可以是客户端

### BitTorrent

协议描述了如何文件分发。

（结构？）首先将文件分割成等长的块（如256KB），然后对等方的集合称为洪流，每个对等方拥有一个tracker来随机获得其他对等方的集合子集，我们假定为50个对等方作为邻居。

（请求什么？向谁请求？）紧接着使用最稀缺优先技术，使每次请求都优先请求邻居最稀缺同时自己缺少的块，保证更迅速的稀缺块分发，同时每10秒确定上传请求文件块最快的四个邻居，称为疏通，来决定向谁请求文件块。

（怎么回应？）紧接着每30秒，随机回应请求发送文件块。

## 视频流和内容分发网

### 因特网视频



### HTTP流和DASH

480p，720p就是描述DASH的，拥有用户调整和自适应和缩略图帧的功能。

### 内容分发网

CDN（内容分发网）来分布存储视频，而不是集中式数据中心。

### 学习案例



## 套接字编程

直接作为wireshark实验的通关记录：

   

### UDP套接字编程



### TCP套接字编程



